<div class="sessions"> <!-- Container for the audio recording session -->
    <div class="audio" id="audio"> <!-- Container for the audio controls -->
        <!-- Image for the record button -->
        <img id="record-icon" class="mic-icon" src="{{ url_for('static', filename='img/miciconmuted.svg') }}" alt="Record Icon">
        <!-- Image for the stop button, initially hidden -->
        <img id="stop-icon" class="mic-icon" src="{{ url_for('static', filename='img/mic_icon.svg') }}" alt="Stop Icon" style="display: none;">
        <p></p> <!-- Empty paragraph element for potential future use -->
        <div id="level-display" class="level-display"> <!-- Container for the audio level display -->
            <div id="level-bar" class="level-bar"></div> <!-- Bar representing the audio level -->
        </div>
    </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/wave-resampler"></script> <!-- External script for resampling audio -->

<script>    
const recordIcon = document.getElementById("record-icon"); // Get the record icon element
const stopIcon = document.getElementById("stop-icon"); // Get the stop icon element
const levelDisplay = document.getElementById("level-display"); // Get the level display container
const levelBar = document.getElementById("level-bar"); // Get the level bar

startedRecording = false; // Flag to track if recording has started

// Function to update the audio level display
function updateLevel() {
    let dataArray = new Uint8Array(analyserNode.frequencyBinCount); // Create an array to hold audio data
    analyserNode.getByteFrequencyData(dataArray); // Populate array with audio data
    
    let total = dataArray.reduce((sum, value) => sum + value, 0); // Sum the audio data
    let average = total / dataArray.length; // Calculate the average audio level
    let level = average / 256; // Normalize the audio level
    levelBar.style.width = level * 100 + "%"; // Set the width of the level bar based on the audio level

    requestAnimationFrame(updateLevel); // Request the next animation frame to update the level
}

// Node class for creating a linked list
class Node {
  constructor(data) {
    this.data = data;
    this.next = null;
  }
}

// Queue class for handling audio data
class Queue {
  constructor() {
    this.front = null;
    this.rear = null;
    this.size = 0;
    this.sending = 0;
  }

  // Add an item to the rear of the queue
  enqueue(data) {
    const node = new Node(data);
    if (!this.front) {
      this.front = node;
      this.rear = node;
    } else {
      this.rear.next = node;
      this.rear = node;
    }
    this.size++;
  }

  // Remove an item from the front of the queue
  dequeue() {
    if (!this.front) {
      return null;
    }
    const node = this.front;
    this.front = this.front.next;
    if (!this.front) {
      this.rear = null;
    }
    this.size--;
    return node.data;
  }

  // Get the current size of the queue
  getSize() {
    return this.size;
  }
}

// Function to concatenate Int16 arrays
function concatenateInt16Arrays(queue, size) {
  chunk = queue.dequeue(); // Dequeue the first chunk of data

  // Create a new Int16Array with the combined length
  let concatenatedArray = new Int16Array(size * chunk.length);

  // Copy the contents of each array into the concatenated array
  for (let i = 0; i < size - 1; i++) {
    concatenatedArray.set(chunk, i * chunk.length);
    chunk = queue.dequeue();
  }
  concatenatedArray.set(chunk, (size - 1) * chunk.length);

  return concatenatedArray;
}

// Function to convert Float32 array to Int16 array
function convertFloat32ToInt16(buffer) {
  l = buffer.length;
  buf = new Int16Array(l);
  while (l--) {
    buf[l] = buffer[l] * 0x7FFF;
  }
  return buf;
}

let time = Date.now(); // Get the current time
let analyserNode; // Variable to hold the analyser node
let sent_pause = 0; // Flag to track if pause has been sent

const queue = new Queue(); // Create a new queue
const chunksize = 16384; // Define the chunk size for audio processing

// Function to create and initialize the audio context
function createAudioContext() {
  const audioContext = new AudioContext(); // Create an AudioContext instance

  // Create a MediaStreamSource from the user's microphone
  navigator.mediaDevices.getUserMedia({ audio: true, video: false }).then((stream) => {
    audioSource = audioContext.createMediaStreamSource(stream);
    processor = audioContext.createScriptProcessor(chunksize, 1, 1);
    audioSource.connect(processor);
    processor.connect(audioContext.destination);

    const sampleRate = audioContext.sampleRate;

    analyserNode = audioContext.createAnalyser();
    audioSource.connect(analyserNode);
    requestAnimationFrame(updateLevel); // Start updating the audio level display

    // Process audio data
    processor.onaudioprocess = (event) => {
      if (stopIcon.style.display !== "none") {
        const audioFloat32 = event.inputBuffer.getChannelData(0); // Get audio data
        const audioFloat32_resampled = Float32Array.from(waveResampler.resample(audioFloat32, audioContext.sampleRate, 16000));
        const audioInt16 = convertFloat32ToInt16(audioFloat32_resampled); // Convert audio data to Int16
        queue.enqueue(audioInt16); // Enqueue the audio data
      }
    }
  });
}

// Periodically send audio data to the server
setInterval(function() {
  const size = queue.getSize();
  if (size > 0 && queue.sending === 0) {
    queue.sending = 1;

    const audioInt16 = concatenateInt16Arrays(queue, size);

    var audioString = '';
    var bytes = new Uint8Array(audioInt16.buffer);
    for (var i = 0; i < bytes.length; i++) {
      audioString += String.fromCharCode(bytes[i]);
    }

    time += audioString.length / 32; // pcm_s16le has 32 bytes per millisecond
    message = { "b64_enc_pcm_s16le": btoa(audioString), "start": time / 1000 };
    if (typeof speaker !== 'undefined') {
      message["speaker"] = speaker;
    }
    console.log("Send to stream: {{ stream }}")
    console.log('{{ server }}/{{ session }}/{{ stream }}/append')
    fetch('{{ server }}/{{ session }}/{{ stream }}/append', {
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(JSON.stringify(message))
    })
    .then(response => {
      queue.sending = 0;
      sent_pause = 0;
    })
    .catch(error => {
      console.log("ERROR in post request!");
      queue.sending = 0;
    });

  } else if (sent_pause === 0 && stopIcon.style.display === "none") {
    sent_pause = 1;
    console.log("SENDING PAUSE");
    message = { "b64_enc_pcm_s16le": btoa("PAUSE") };
    fetch('{{ server }}/{{ session }}/{{ stream }}/append', {
      method: 'POST',
      headers: {
        'Accept': 'application/json',
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(JSON.stringify(message))
    });
  }
}, 100);

// Function to start recording
function recording() {
  if (!startedRecording) {
    createAudioContext(); // Initialize the audio context
    startedRecording = true;
  }
  time = Date.now(); // Reset the time
  recordIcon.style.display = "none"; // Hide the record icon
  stopIcon.style.display = "inline-block"; // Show the stop icon
  levelBar.style.display = "block"; // Show the level bar
}

// Add event listener to start recording when the record icon is clicked
recordIcon.addEventListener("click", function() {
  recording();
});

// Function to stop recording
function stop_recording() {
  stopIcon.style.display = "none"; // Hide the stop icon
  recordIcon.style.display = "inline-block"; // Show the record icon
  levelBar.style.display = "none"; // Hide the level bar
}

// Add event listener to stop recording when the stop icon is clicked
stopIcon.addEventListener("click", function() {
  stop_recording();
});

// Check if correction mode is deactivated and stop or start recording accordingly
// {% if correction_mode_deactivated == True %}
//   stop_recording();
// {% else %}
//   recording();
// {% endif %}

// Object to keep track of key states
var keyState = {};

console.log("Requesting keyboard stream");


// Request to add a stream log for keyboard events
fetch('{{ server }}/{{ session }}/addstreamlog', {
  method: 'POST',
})
.then(stream => stream.text())
.then(stream => {

console.log("Got stream " + stream);
console.log("Got server " + stream);
console.log('{{ server }}/{{ session }}/addstreamlog')

const url = `${server}/${session}/append`;
console.log("URL:", url); // This will print the URL to the console

// Event listener for keydown events
document.addEventListener('keydown', function(event) {
  // Check if the key is already pressed
  if (!keyState[event.key]) {
    time_ = Date.now();
    // Key is not pressed, so log it and set its state to pressed
    console.log('Key pressed: ' + event.key + ' ' + time_ / 1000);

    data = { "keyboard_press": event.key, "time": time_ / 1000 };

    // Send key press data to the server
    fetch('{{ server }}/{{ session }}/' + stream + '/append', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify(JSON.stringify(data)),
    });

    keyState[event.key] = true;
    // You can add your custom logic here
  }
});

// Event listener for keyup events
document.addEventListener('keyup', function(event) {
  time_ = Date.now();

  // Log that the key is released and set its state to released
  console.log('Key released: ' + event.key + ' ' + time_ / 1000);

  data = { "keyboard_release": event.key, "time": time_ / 1000 };

  // Send key release data to the server
  fetch('{{ server }}/{{ session }}/' + stream + '/append', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify(JSON.stringify(data)),
  });

  keyState[event.key] = false;
  // You can add your custom logic here
});

});
</script>

    